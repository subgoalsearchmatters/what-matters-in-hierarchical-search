algorithm:

  # SolveInstances has parameters:
    #   - solver_class - this class is responsible for solving the problem. It has parameters:
    #           - max_nodes - maximum number of nodes to be expanded
    #           - planner_class - this class is responsible for planning the path
    #           - subgoal_generator - this class is responsible for generating subgoals
    #           - validator - this class is responsible for validating the plan, i.e. checking if there is a path from the initial state to the goal state
    #           - cllp - this class is responsible for executing the plan, i.e. executing the actions in the plan, i.e. finding the path from the initial state to the goal state
    #           - value_function - this class is responsible for evaluating the state, i.e. estimating the distance from the state to the solution
    #   - data_loader_class - this class is responsible for loading the data to be solved
    #   - result_logger - this class is responsible for logging the results
    #   - problem_to_solve - number of problems to be solved
    #   - n_parallel_workers - number of parallel workers, i.e. number of processes to be used


  _target_: carl.solve_instances.solve_instances.SolveInstances

  # solver class
  solver_class:
    _target_: carl.solver.subgoal_search.Solver
    max_nodes: 2000
    planner_class:
      _partial_: true
      _target_: carl.solver.planners.BestFSPlanner

    subgoal_generator:
      _target_: carl.inference_components.policy.PolicyGeneratorWrapper
      policy:
        _target_: carl.inference_components.policy.TransformerPolicy
        policy_network:
          _target_: transformers.BertForSequenceClassification
          config:
            _target_: transformers.BertConfig
        path_to_policy_weights: path_to_policy_weights
        env:
          _target_: carl.environment.sokoban.env.SokobanEnv
          tokenizer:
            _target_: carl.environment.sokoban.tokenizer.SokobanTokenizer
            cut_distance: 150
            type_of_value_training: "regression"
            size_of_board:
              - 12
              - 12
          num_boxes: 4
        # if confidence_threshold is None, then the n_actions parameter is used.
        n_actions: None
        confidence_threshold: 0.0
      env:
        _target_: carl.environment.sokoban.env.SokobanEnv
        tokenizer:
          _target_: carl.environment.sokoban.tokenizer.SokobanTokenizer
          cut_distance: 150
          type_of_value_training: "regression"
          size_of_board:
            - 12
            - 12
        num_boxes: 4

    # validator
    validator:
      _target_: carl.inference_components.validator.DummyValidator
      env:
        _target_: carl.environment.sokoban.env.SokobanEnv
        tokenizer:
          _target_: carl.environment.sokoban.tokenizer.SokobanTokenizer
          cut_distance: 150
          type_of_value_training: "regression"
          size_of_board:
            - 12
            - 12
        num_boxes: 4

    # value function
    value_function:
      _target_: carl.inference_components.value.TransformerValue
      value_network:
        _target_: transformers.BertForSequenceClassification
        config:
          _target_: transformers.BertConfig
      path_to_value_network_weights: path_to_value_weights
      type_of_evaluation: "regression"
      noise_variance: 0.85
      env:
        _target_: carl.environment.sokoban.env.SokobanEnv
        tokenizer:
          _target_: carl.environment.sokoban.tokenizer.SokobanTokenizer
          cut_distance: 150
          type_of_value_training: "regression"
          size_of_board:
            - 12
            - 12
        num_boxes: 4

  # data loader class
  data_loader_class:
    _target_: carl.environment.instance_generator.BasicInstanceGenerator
    generator:
      _target_: carl.environment.instance_generator.GeneralIterableDataLoader
      path_to_folder_with_data: path_to_folder_with_data
    batch_size: 1

  # result logger
  result_logger: null

  n_parallel_workers: 1

